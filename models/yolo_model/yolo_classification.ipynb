{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11n-cls.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.53 available ðŸ˜ƒ Update with 'pip install -U ultralytics'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\nicho\\Documents\\FYP\\datasets\\vipr_dataset\\masked_3\\train... 17117 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17117/17117 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\nicho\\Documents\\FYP\\datasets\\vipr_dataset\\masked_3\\train... 17117 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17117/17117 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\nicho\\Documents\\FYP\\datasets\\vipr_dataset\\masked_3\\test... 4280 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4280/4280 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\nicho\\Documents\\FYP\\datasets\\vipr_dataset\\masked_3\\test... 4280 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4280/4280 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/1070 [00:00<?, ?it/s]\n",
      "      1/100      1.78G      1.755         16        640:   0%|          | 0/1070 [00:06<?, ?it/s]\n",
      "      1/100      1.78G      1.755         16        640:   0%|          | 1/1070 [00:06<2:03:40,  6.94s/it]\n",
      "      1/100      1.78G      1.737         16        640:   0%|          | 1/1070 [00:08<2:03:40,  6.94s/it]\n",
      "      1/100      1.78G      1.737         16        640:   0%|          | 2/1070 [00:08<1:02:27,  3.51s/it]\n",
      "      1/100      1.78G      1.737         16        640:   0%|          | 2/1070 [00:11<1:43:59,  5.84s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 972, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 806, in train\n",
      "    self.trainer.train()\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 207, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 388, in _do_train\n",
      "    self.scaler.scale(self.loss).backward()\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\site-packages\\torch\\_tensor.py\", line 581, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\site-packages\\torch\\autograd\\graph.py\", line 825, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Exception in thread Thread-4 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 59, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 35, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\multiprocessing\\queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 560, in rebuild_storage_filename\n",
      "    storage = torch.UntypedStorage._new_shared_filename_cpu(manager, handle, size)\n",
      "RuntimeError: Couldn't open shared event: <torch_8268_3569191057_0_event>, error code: <2>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ultralytics 8.3.47 ðŸš€ Python-3.10.15 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=../../datasets/vipr_dataset/masked_3/, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train5\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\nicho\\Documents\\FYP\\datasets\\vipr_dataset\\masked_3\\train... found 17117 images in 5 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\nicho\\Documents\\FYP\\datasets\\vipr_dataset\\masked_3\\test... found 4280 images in 5 classes âœ… \n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    336645  ultralytics.nn.modules.head.Classify         [256, 5]                      \n",
      "YOLO11n-cls summary: 151 layers, 1,537,509 parameters, 1,537,509 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train5\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    }
   ],
   "source": [
    "# Start training from a pretrained *.pt model\n",
    "! yolo classify train data=../../datasets/vipr_dataset/masked_3/ model=yolo11n-cls.pt epochs=100 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 900, in entrypoint\n",
      "    check_dict_alignment(full_args_dict, {a: \"\"})\n",
      "  File \"C:\\Users\\nicho\\anaconda3\\envs\\YOLO\\lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 485, in check_dict_alignment\n",
      "    raise SyntaxError(string + CLI_HELP_MSG) from e\n",
      "SyntaxError: '\u001b[31m\u001b[1m#\u001b[0m' is not a valid YOLO argument. \n",
      "\n",
      "    Arguments received: ['yolo', 'classify', 'val', 'model=yolo11n-cls.pt', '#', 'validate', 'the', 'trained', 'model']. Ultralytics 'yolo' commands use the following syntax:\n",
      "\n",
      "        yolo TASK MODE ARGS\n",
      "\n",
      "        Where   TASK (optional) is one of {'obb', 'classify', 'pose', 'segment', 'detect'}\n",
      "                MODE (required) is one of {'train', 'track', 'val', 'benchmark', 'export', 'predict'}\n",
      "                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n",
      "                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n",
      "\n",
      "    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n",
      "        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n",
      "\n",
      "    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n",
      "        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n",
      "\n",
      "    3. Val a pretrained detection model at batch-size 1 and image size 640:\n",
      "        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n",
      "\n",
      "    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n",
      "        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n",
      "\n",
      "    5. Streamlit real-time webcam inference GUI\n",
      "        yolo streamlit-predict\n",
      "\n",
      "    6. Ultralytics solutions usage\n",
      "        yolo solutions count or in ['heatmap', 'queue', 'speed', 'workout', 'analytics', 'trackzone'] source=\"path/to/video/file.mp4\"\n",
      "\n",
      "    7. Run special commands:\n",
      "        yolo help\n",
      "        yolo checks\n",
      "        yolo version\n",
      "        yolo settings\n",
      "        yolo copy-cfg\n",
      "        yolo cfg\n",
      "        yolo solutions help\n",
      "\n",
      "    Docs: https://docs.ultralytics.com\n",
      "    Solutions: https://docs.ultralytics.com/solutions/\n",
      "    Community: https://community.ultralytics.com\n",
      "    GitHub: https://github.com/ultralytics/ultralytics\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "! yolo classify val model=yolo11n-cls.pt  # validate the trained model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
